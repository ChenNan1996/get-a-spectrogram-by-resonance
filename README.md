# get-a-spectrogram-by-resonance
基于共振原理计算语音信号的声谱图

笔者通过查阅教科书《生理学基础》了解到人耳实际是通过耳蜗的独特构造使得传入的声音在不同部位产生的振动幅度不同。各个部位对特定频率的声音更敏感，从而产生了频域*时域的二维神经信号。这种方式显然比较灵活 ，对于需要的频率区间，可以通过更密集的神经细胞来获取更详细的信息。

之后笔者通过浏览与振动相关的资料，了解到了共振的概念。但通过谷歌搜索，未找到基于共振原理计算声谱图的内容，于是产生了自己动手实现的想法。相比傅里叶变换将信号分解到一组正交基的做法，通过共振计算声谱图显得低效且信息冗余，但毕竟STFT也不是完全准确的，共振的方式由于更贴近人耳，或许能捕捉到更多有用的信息，从而可能有助于语音识别和合成。因此值得做下尝试。

笔者参考相关资料，推导了有阻尼系统对简谐信号的响应公式。但由于实际的语音信号是离散的数据，无法用公式计算系统响应x(t)。因此假设相邻的两点是线性连续的，然后逐个点的计算下一时刻的x、v。在处理几秒、十几秒的数据时，笔者通过分析认为此假设带来的误差影响非常小。

基于这个方式，可以通过构建一组对特定频率敏感的系统，然后输入语音信号得到一组响应，再对响应的长度进行压缩来得到声谱图。代码请见spcg-by-resonance.py。

此外，笔者分析了系统参数对时域、频域分辨率的影响，并发现和其他计算声谱图的方式一样，也存在时域频域权衡的问题。同时也发现了掩蔽效应的存在，而这和人耳的情况是吻合的。

最后是个和声谱图无关的话题，笔者发现将响应直接相加能得到清晰的语音，但整体音色有所变化，于是对这个现象进行了大致的分析。

详细内容请见pdf文档《基于共振原理计算语音信号的声谱图》
